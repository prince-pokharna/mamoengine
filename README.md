# ğŸš€ Market-Mood Engine

Predict what consumers will want BEFORE trends become mainstream using AI sentiment analysis and trend forecasting.

## ğŸ“‹ Problem

Businesses spend millions predicting consumer demand with outdated methods. Market-Mood detects emerging trends in real-time by analyzing news, social media, and e-commerce patterns across Indian markets.

## ğŸ’¡ Solution

A real-time AI system that:
- Analyzes sentiment across 5+ data sources
- Detects emerging trends before competitors
- Forecasts demand 1-4 weeks ahead
- Provides actionable intelligence via API + dashboard

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DATA SOURCES (Real + Mock)                  â”‚
â”‚  News API â”‚ Twitter â”‚ Google Trends â”‚ Ecommerce    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Data Ingestion & Validationâ”‚
        â”‚      (Hourly batch)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     SQLite Database        â”‚
        â”‚  (articles, tweets, etc.)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  NLP & Sentiment Analysis (BERT)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Trend Detection & Forecasting    â”‚
        â”‚    (ARIMA, Prophet, LSTM)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  REST API + Streamlit Dashboard  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš¡ Quick Start

### 1. Setup Environment

```bash
# Clone and navigate to repository
cd market-mood-engine

# Install dependencies
pip install -r requirements.txt

# Setup environment variables
cp .env.example .env
# Edit .env and add your API keys
```

### 2. Configure API Keys (Optional)

Get API keys from:
- **News API**: https://newsapi.org/ (free tier)
- **Twitter API**: https://developer.twitter.com/ (free tier)
- **Google Trends**: No API key needed (uses pytrends)

Add to `.env` file:
```
NEWS_API_KEY=your_newsapi_key
TWITTER_API_KEY=your_twitter_key
TWITTER_API_SECRET=your_twitter_secret
TWITTER_ACCESS_TOKEN=your_access_token
TWITTER_ACCESS_TOKEN_SECRET=your_access_secret
```

> **Note**: The system works with mock data if API keys are not configured, perfect for testing!

### 3. Initialize Database

```bash
python -c "from src.database import DatabaseManager; import config; db = DatabaseManager(config.DB_PATH); db.create_tables(); print('Database initialized!')"
```

### 4. Run Data Collection

```bash
# Test the pipeline
python test_pipeline.py

# Or run data ingestion directly
python src/data_ingestion.py
```

### 5. Schedule Hourly Collection (Optional)

**Windows (Task Scheduler):**
```powershell
# Create a task to run hourly
schtasks /create /tn "MarketMoodCollection" /tr "python D:\mamoengine\src\data_ingestion.py" /sc hourly
```

**Linux/Mac (Cron):**
```bash
# Add to crontab
0 * * * * cd /path/to/market-mood-engine && python src/data_ingestion.py
```

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Data Sources** | NewsAPI, Twitter API, Google Trends, SQLite |
| **NLP** | Hugging Face Transformers (DistilBERT) |
| **Machine Learning** | scikit-learn, PyTorch, Statsmodels |
| **Time Series** | ARIMA, Prophet, LSTM |
| **API** | FastAPI + Uvicorn |
| **Dashboard** | Streamlit |
| **Deployment** | Docker |

## ğŸ“Š Key Features

### âœ… Day 1-2: Data Pipeline (COMPLETED)
- âœ… Multi-source data collection (News, Twitter, Google Trends)
- âœ… SQLite database with optimized schema
- âœ… Mock data generators for testing
- âœ… Error handling & retry logic
- âœ… Duplicate detection
- âœ… Production-ready logging

### â³ Day 3: Sentiment Analysis (UPCOMING)
- Transformer-based sentiment analysis (DistilBERT)
- Entity extraction & aspect-based sentiment
- Emotion classification
- Confidence scoring

### â³ Day 4: Trend Detection (UPCOMING)
- Sentiment velocity tracking
- Cross-source trend validation
- Early warning system
- Trend strength scoring

### â³ Day 5: Forecasting (UPCOMING)
- Multi-model ensemble (ARIMA + Prophet + LSTM)
- 1-4 week demand forecasting
- Concept drift detection
- Confidence intervals

### â³ Day 6: API + Dashboard (UPCOMING)
- REST API endpoints
- Interactive Streamlit dashboard
- Real-time updates
- Data visualization

### â³ Day 7: Testing + Polish (UPCOMING)
- Unit & integration tests
- Docker containerization
- Documentation
- Production deployment guide

## ğŸ“ Project Structure

```
market-mood-engine/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw data files (gitignored)
â”‚   â”œâ”€â”€ processed/           # Processed data (gitignored)
â”‚   â””â”€â”€ market_mood.db       # SQLite database (gitignored)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py          # Package initialization
â”‚   â”œâ”€â”€ database.py          # Database manager
â”‚   â”œâ”€â”€ data_ingestion.py    # Data collection pipeline
â”‚   â”œâ”€â”€ models.py            # Pydantic data models
â”‚   â”œâ”€â”€ sentiment_analyzer.py    # (Day 3)
â”‚   â”œâ”€â”€ trend_detector.py        # (Day 4)
â”‚   â””â”€â”€ forecaster.py            # (Day 5)
â”œâ”€â”€ notebooks/               # Jupyter notebooks for analysis
â”œâ”€â”€ tests/                   # Unit tests
â”œâ”€â”€ config.py               # Configuration management
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ test_pipeline.py        # Pipeline testing script
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ .gitignore             # Git ignore rules
â””â”€â”€ README.md              # This file
```

## ğŸ¯ Target Metrics

| Metric | Target | Status |
|--------|--------|--------|
| Sentiment Accuracy | 85%+ | â³ Day 3 |
| Trend Detection Precision | 80%+ | â³ Day 4 |
| Forecast MAPE | <15% | â³ Day 5 |
| API Latency (p95) | <200ms | â³ Day 6 |
| Test Coverage | 80%+ | â³ Day 7 |

## ğŸ“ˆ Current Status

**ğŸš§ In Progress - 7 Day Sprint**

| Day | Task | Status |
|-----|------|--------|
| **Day 1-2** | Data Pipeline Foundation | âœ… **COMPLETED** |
| **Day 3** | Sentiment Analysis | â³ Pending |
| **Day 4** | Trend Detection | â³ Pending |
| **Day 5** | Forecasting Models | â³ Pending |
| **Day 6** | API + Dashboard | â³ Pending |
| **Day 7** | Testing + Polish | â³ Pending |

### Day 1-2 Achievements âœ…
- âœ… Complete data ingestion pipeline with 5 collectors
- âœ… SQLite database with optimized schema & indexes
- âœ… Production-grade error handling & retry logic
- âœ… Mock data generators for testing without API keys
- âœ… Comprehensive logging system
- âœ… Data deduplication by URL/text/date
- âœ… Tested and verified - collecting 30+ data points per run

## ğŸ§ª Testing

Run the test suite:
```bash
python test_pipeline.py
```

Expected output:
```
[SUCCESS] ALL TESTS PASSED - Day 1 Complete!
Articles collected: 5
Tweets collected: 10
Trends collected: 5
Sales collected: 5
Reddit posts collected: 5
```

## ğŸ” Example Usage

```python
from src.database import DatabaseManager
from src.data_ingestion import DataPipeline
import config

# Initialize
db = DatabaseManager(config.DB_PATH)
db.create_tables()

# Collect data
pipeline = DataPipeline(db)
stats = pipeline.run_hourly()

# Query recent data
recent_data = db.get_recent_data(hours=24)
print(f"Articles: {len(recent_data['articles'])}")
print(f"Tweets: {len(recent_data['tweets'])}")

# Get statistics
db_stats = db.get_stats()
print(f"Total records: {db_stats}")
```

## ğŸ¤ Contributing

This is a portfolio/learning project following a structured 7-day sprint. Contributions and feedback are welcome!

## ğŸ“ License

MIT License - Feel free to use this for learning and portfolio purposes.

## ğŸ“ Learning Outcomes

This project demonstrates:
- Production-grade data pipeline design
- Multi-source data integration
- NLP & sentiment analysis
- Time series forecasting
- REST API development
- Dashboard creation
- Docker containerization
- Testing & documentation best practices

---

**Built with â¤ï¸ as part of a 7-day intensive learning sprint**

Last Updated: Day 2 - December 7, 2025

